# 집합에 만개의 랜덤한 숫자를 넣는것과, 배열에 만개의 랜덤한 숫자를 넣는것 중 어떤게 더 빠를까요?

```swift
var array: [Int] = []

var set: Set<Int> = []

for _ in 0..<1000 {
    array.append(Int.random(in: 0..<1000000))
}

for _ in 0..<1000 {
    `set`.insert(Int.random(in: 0..<1000000))
}
```

처음에는 두 속도가 크게 차이 나지 않을 것 같다는 생각했다. 미세하기 차이가 나더라도 그건 set이 Array와 달리 중복된 값을 처리하지 않기 때문에, 값을 메모리에 할당하는 과정이 없어서 조금 더 빠르지 않을까 하는 생각이었는데, 실제로 코드를 실행해보면 미세한 정도가 아니라 눈에 띄게 속도가 차이나는 것을 확인할 수 있었다.

[관련 블로그](https://sujinnaljin.medium.com/swift-array-의-capacity-9c3a99d2c31f)

이유는 Array 객체의 **[capacity](https://developer.apple.com/documentation/swift/array/capacity)** 프로퍼티를 통해 알 수 있었다. capacity는 새로운 메모리 할당 없이, 몇 개의 element를 추가할 수 있는 지를 나타내는 프로퍼티이다.

Swift에서 Array는 기본적으로 동적 크기를 가지는데, 위 예제의 경우 array는 빈 배열로 선언되었으므로 capacity가 0이다.

값을 추가하면 capacity도 증가하게 되는데 여기가 중요한 포인트였다.

Array가 동적 크기이다 보니 기존에 할당된 메모리가 다 차게 되면 원래의 capacity(할당된 메모리)의 두 배 크기만큼 새로운 공간을 할당하고, 이 영역으로 본래의 값을 복사하는 방식이었다.

그리고 값을 복사하는 과정에서 O(N)만큼의 시간이 걸리는 것이다.

실제로 for문 안에 capacity를 찍어보면, 0, 2, 4, 8, 16 … 이런 식으로 증가하는 걸 볼 수 있었다.

공식 문서를 보면 새 스토리지는 이전 스토리지 크기의 배수라는데, 꼭 2배는 아닌 것 같았다. 중간에 64 이후에 188, 380, 764 이런식으로 증가하는 걸 볼 수 있었다.

그런데도 문서에서 append의 시간복잡도를 O(1)이라고 적혀있는데 찾아보니 배열의 용량이 증가함에 따라 배열 크기를 늘리는 횟수가 점점 줄어들고 매번 수행되는 과정이 아니라서 O(1)이라고 하는 것 같았다.

궁금했던 점은 2배씩 계속 늘리면 나중에는 너무 큰 값의 배수로 늘려야해서 메모리가 낭비되지 않을까 하는 생각이 들었다. 꼭 2배씩 늘어나지 않는 것처럼 스위프트가 알아서 최적화를 하는 건가?

반면 집합의 insert 연산의 경우 해시연산에 따라 다음과 같은 연산을 수행한다.

1. 해당 요소의 해시 값을 계산
2. 해시 함수를 사용하여 그 해시 값에서 버킷의 인덱스를 도출
3. 그 인덱스에 해당하는 버킷에 요소를 저장. 만약 그 위치에 이미 다른 요소가 있으면 (해시 충돌), 링크드리스트로 연결하거나 사이즈를 늘린다.

따라서 array보다 값을 복사하는 시간이 들지 않거나 적게 들어서 빠른게 아닌가 하는 생각이 들었다.

여기서도 궁금했던 점은 버킷도 결국 충돌이 나면 사이즈를 늘린 새로운 버킷을 생성하고 요소들을 새롭게 배치해야하는데 똑같이 O(N)이 걸리는게 아닐까?

처음부터 버킷의 크기가 크게 정해져있고, 2배씩 늘어나는게 아니라 다른 방식(요소의 최대개수보다 큰 소수)으로 늘어나서 값을 복사할 일이 적은 것일까?
